{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e81f5aa",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a045dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,cross_validate\n",
    "from sklearn.metrics import classification_report,make_scorer,confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE,ADASYN,BorderlineSMOTE,SMOTEN,SVMSMOTE,KMeansSMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids,RandomUnderSampler,NearMiss\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e2445",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96ea171",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 23873\n",
    "dt = pd.read_excel(r'CA_BC.xlsx').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9642b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.columns = dt.iloc[0]\n",
    "dt = dt.iloc[1:]\n",
    "dt['Label'] = dt.Label.map({'E':1,'A':0})\n",
    "dt.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce91265",
   "metadata": {},
   "source": [
    "#### Duplicate Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f42b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to not rename\n",
    "excluded = dt.columns[~dt.columns.duplicated(keep=False)]\n",
    "\n",
    "# An incrementer\n",
    "import itertools\n",
    "inc = itertools.count().__next__\n",
    "\n",
    "# A renamer\n",
    "def ren(name):\n",
    "    return f\"{name}{inc()}\" if name not in excluded else name\n",
    "\n",
    "# Use inside rename()\n",
    "for x in range(0,2):\n",
    "    dt.rename(columns=ren,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835c9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dt.select_dtypes(include=['object']).columns:\n",
    "    dt[x] = dt[x].astype('float64')\n",
    "dt.columns = [str(x) for x in dt.columns]\n",
    "dt = dt.select_dtypes(include=['float64','int64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07a60f",
   "metadata": {},
   "source": [
    "### Baseline Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b0eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:22<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "features = dt.copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4c2bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "Empty DataFrame\n",
      "Columns: Index(['Accuracy', 'Balanced Accuracy', 'ROC AUC', 'F1 Score', 'Time Taken'], dtype='object')\n",
      "Index: Float64Index([], dtype='float64', name='Model') \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9675ec0",
   "metadata": {},
   "source": [
    "### Importing from previous study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad982672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_columns(dt,x):\n",
    "    dt.columns = [f'{y}_{x}' for y in dt.columns]\n",
    "    return dt\n",
    "files = ['baseline','pearson','chi','ig','rfe']\n",
    "dataframes = [pd.read_csv(f'{x}.csv').set_index('Model') for x in files]\n",
    "for x in range(len(files)):\n",
    "    dataframes[x].columns = [f'{y}_{files[x]}' for y in dataframes[x].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1418d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "baseline_merged = reduce(lambda  left,right: pd.merge(left,right,on='Model',\n",
    "                                            how='inner'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f2b1897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score_baseline</th>\n",
       "      <th>F1 Score_pearson</th>\n",
       "      <th>F1 Score_chi</th>\n",
       "      <th>F1 Score_ig</th>\n",
       "      <th>F1 Score_rfe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               F1 Score_baseline  F1 Score_pearson  \\\n",
       "Model                                                                \n",
       "AdaBoostClassifier                          0.92              0.82   \n",
       "LGBMClassifier                              0.87              0.92   \n",
       "XGBClassifier                               0.87              0.95   \n",
       "ExtraTreesClassifier                        0.87              0.85   \n",
       "RidgeClassifierCV                           0.84              0.89   \n",
       "RidgeClassifier                             0.84              0.89   \n",
       "BaggingClassifier                           0.84              0.87   \n",
       "LogisticRegression                          0.81              0.89   \n",
       "LinearDiscriminantAnalysis                  0.81              0.89   \n",
       "RandomForestClassifier                      0.81              0.89   \n",
       "BernoulliNB                                 0.77              0.87   \n",
       "KNeighborsClassifier                        0.79              0.87   \n",
       "PassiveAggressiveClassifier                 0.73              0.89   \n",
       "NearestCentroid                             0.74              0.87   \n",
       "LinearSVC                                   0.70              0.89   \n",
       "DecisionTreeClassifier                      0.68              0.90   \n",
       "Perceptron                                  0.65              0.89   \n",
       "SGDClassifier                               0.65              0.89   \n",
       "QuadraticDiscriminantAnalysis               0.55              0.87   \n",
       "ExtraTreeClassifier                         0.66              0.74   \n",
       "CalibratedClassifierCV                      0.67              0.89   \n",
       "NuSVC                                       0.65              0.89   \n",
       "LabelSpreading                              0.14              0.79   \n",
       "LabelPropagation                            0.14              0.79   \n",
       "DummyClassifier                             0.57              0.57   \n",
       "SVC                                         0.57              0.89   \n",
       "GaussianNB                                  0.58              0.89   \n",
       "\n",
       "                               F1 Score_chi  F1 Score_ig  F1 Score_rfe  \n",
       "Model                                                                   \n",
       "AdaBoostClassifier                     0.87         0.82          0.95  \n",
       "LGBMClassifier                         0.85         0.92          0.97  \n",
       "XGBClassifier                          0.87         0.92          0.97  \n",
       "ExtraTreesClassifier                   0.89         0.95          0.92  \n",
       "RidgeClassifierCV                      0.89         0.92          0.92  \n",
       "RidgeClassifier                        0.89         0.92          0.92  \n",
       "BaggingClassifier                      0.78         0.85          0.90  \n",
       "LogisticRegression                     0.89         0.95          0.92  \n",
       "LinearDiscriminantAnalysis             0.89         0.92          0.92  \n",
       "RandomForestClassifier                 0.85         0.95          0.93  \n",
       "BernoulliNB                            0.90         0.92          0.95  \n",
       "KNeighborsClassifier                   0.83         0.92          0.95  \n",
       "PassiveAggressiveClassifier            0.77         0.92          0.90  \n",
       "NearestCentroid                        0.92         0.95          0.92  \n",
       "LinearSVC                              0.87         0.95          0.92  \n",
       "DecisionTreeClassifier                 0.69         0.78          0.84  \n",
       "Perceptron                             0.80         0.89          0.93  \n",
       "SGDClassifier                          0.87         0.95          0.95  \n",
       "QuadraticDiscriminantAnalysis          0.20         0.92          0.90  \n",
       "ExtraTreeClassifier                    0.70         0.85          0.79  \n",
       "CalibratedClassifierCV                 0.89         0.95          0.92  \n",
       "NuSVC                                  0.87         0.95          0.92  \n",
       "LabelSpreading                         0.79         0.87          0.92  \n",
       "LabelPropagation                       0.79         0.87          0.92  \n",
       "DummyClassifier                        0.57         0.57          0.57  \n",
       "SVC                                    0.92         0.92          0.92  \n",
       "GaussianNB                             0.87         0.92          0.92  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_merged[['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2a05f",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n",
    "### Remove Co-Linear Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1444ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://chrisalbon.com/code/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "# corr = dt.corr()\n",
    "\n",
    "# # sns.heatmap(corr)\n",
    "\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = corr.abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# print(f\"Would drop {len(to_drop)} fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edff96f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23944\\2241597011.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLazyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodels_corr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_drop' is not defined"
     ]
    }
   ],
   "source": [
    "features = dt.drop(to_drop, axis=1).copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_corr,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "models_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c133a4",
   "metadata": {},
   "source": [
    "### Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06659cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_MinMax = MinMaxScaler().fit_transform(x_train)\n",
    "# clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "# models_min_max,predictions=clf.fit(x_train_MinMax, x_test, y_train, y_test)\n",
    "\n",
    "# models_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt.drop(to_drop, axis=1).copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_min_max,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cb86a",
   "metadata": {},
   "source": [
    "#### Both Techniques (scaling & Co-linear Varaibles Reduction) improve performance for Linear Models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e1fef",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7a179",
   "metadata": {},
   "source": [
    "Two Step Selection:\n",
    "- Recursive Feature Elimination (select peak point)\n",
    "- Forward Selection (Find the right mix feature count & performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65dff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_select_log_reg(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    clf = LogisticRegression()\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].coef_[0] for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.drop(to_drop, axis=1).columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_log_reg(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0abde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faad619",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('lrs1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 301\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt.drop(to_drop, axis=1)[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb202298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = LogisticRegression()\n",
    "    scores = cross_val_score(classifiers, StandardScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd475c0a",
   "metadata": {},
   "source": [
    "##### Scorer = f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b85b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt.drop(to_drop, axis=1)[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a435511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('lrs2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4203e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[5][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_lr,predictions=clf.fit(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda89e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pd.merge(baseline_merged,models_lr,left_index=True,right_index=True)\n",
    "lr = lr[lr.index =='LogisticRegression'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd955d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = lr[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('lr_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705efd8c",
   "metadata": {},
   "source": [
    "#### Recall Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78edb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt.drop(to_drop, axis=1)[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96cc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5129516a",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391afb84",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a89762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def feat_select_extra(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', ExtraTreesClassifier(n_estimators =10, random_state = random_state))\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].feature_importances_ for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.drop(to_drop, axis=1).columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_extra(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('ETS1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 10\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = ExtraTreesClassifier(n_estimators =10, random_state = random_state)\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = ExtraTreesClassifier(n_estimators =10, random_state = random_state)\n",
    "    scores = cross_val_score(classifiers, MinMaxScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0e4d1",
   "metadata": {},
   "source": [
    "#### F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6748904",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('ETS2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf236e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b2fe7",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a093cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7eabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267684be",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[7][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_et,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "et = pd.merge(baseline_merged,models_et,left_index=True,right_index=True)\n",
    "et1 = et[et.index =='ExtraTreesClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = et1[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('et_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "et[et.index =='ExtraTreesClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9ccaf",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bf538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def feat_select_rf(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', RandomForestClassifier(n_estimators =10, random_state = random_state))\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].feature_importances_ for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23036380",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_rf(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26607a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('RFS1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 29\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = RandomForestClassifier(n_estimators =10, random_state = random_state)\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = RandomForestClassifier(n_estimators =10, random_state = random_state)\n",
    "    scores = cross_val_score(classifiers, StandardScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a61e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896578d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Columns')\n",
    "plt.ylabel('Scores')\n",
    "plt.savefig('RFS2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bfa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0914c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e457561",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[5][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_et,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "et = pd.merge(baseline_merged,models_et,left_index=True,right_index=True)\n",
    "et1 = et[et.index =='RandomForestClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = et1[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('rf_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "et[et.index =='RandomForestClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2348f96b",
   "metadata": {},
   "source": [
    "#### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e05f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def feat_select_lgbm(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', LGBMClassifier(random_state = random_state))\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].feature_importances_ for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c394b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_lgbm(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84641ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('LGBMS1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a44855",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 401\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LGBMClassifier(random_state = random_state)\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51955a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = LGBMClassifier(random_state = random_state)\n",
    "    scores = cross_val_score(classifiers, MinMaxScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols\n",
    "\n",
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Columns')\n",
    "plt.ylabel('Scores')\n",
    "plt.savefig('LGBMS2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9982d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a08e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a71321",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[5][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_et,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "et = pd.merge(baseline_merged,models_et,left_index=True,right_index=True)\n",
    "et1 = et[et.index =='LGBMClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = et1[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('lg_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "et[et.index =='LGBMClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e297fba",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a645a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def feat_select_ada(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', AdaBoostClassifier(n_estimators =10, random_state = random_state))\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].feature_importances_ for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cab231",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_ada(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67707adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('ADS1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a70ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 35\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = AdaBoostClassifier(n_estimators =10, random_state = random_state)\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = AdaBoostClassifier(n_estimators =10, random_state = random_state)\n",
    "    scores = cross_val_score(classifiers, StandardScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')\n",
    "\n",
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Columns')\n",
    "plt.ylabel('Scores')\n",
    "plt.savefig('ADS2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfeefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')\n",
    "\n",
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()\n",
    "\n",
    "# bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec081461",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[5][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_et,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "et = pd.merge(baseline_merged,models_et,left_index=True,right_index=True)\n",
    "et1 = et[et.index =='AdaBoostClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = et1[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('ad_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "et[et.index =='AdaBoostClassifier'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc274fd4",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def feat_select_svc(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', SVC(kernel='linear'))\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].coef_[0] for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_svc(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39904e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "sns.color_palette(\"deep\")\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res,color='green')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.savefig('SVMS1.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = 22\n",
    "\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.5,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = SVC(kernel='linear')\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")\n",
    "\n",
    "\n",
    "\n",
    "def classifier(x_train, y_train,scoring):\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_state)\n",
    "    classifiers = SVC(kernel='linear')\n",
    "    scores = cross_val_score(classifiers, StandardScaler().fit_transform(x_train), y_train, scoring=scoring, cv=cv)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def feed_forward(unprocessed_cols,current_bestcols,scoring):\n",
    "    results = [classifier(features[current_bestcols + [x]], target,scoring) for x in unprocessed_cols]\n",
    "    current_bestcols = current_bestcols + [unprocessed_cols[results.index(max(results))]]\n",
    "    bestcols.append((max(results), current_bestcols))\n",
    "    unprocessed_cols.pop(results.index(max(results)))\n",
    "    if len(unprocessed_cols) > 0:\n",
    "        print(f\"{len(unprocessed_cols)} columns left to process\")\n",
    "        feed_forward(unprocessed_cols,current_bestcols,scoring)\n",
    "    else:\n",
    "        return bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestcols = []\n",
    "cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "features = dt[cols].copy()\n",
    "target = features.pop('Label')\n",
    "cols = features.columns.tolist()\n",
    "feed_forward(cols,bestcols,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Scores')\n",
    "plt.savefig('SVMS2.eps',bbox_inches = 'tight',dpi=1200,transparent= False, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a871cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[bestcols[5][1] + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(MinMaxScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_et,predictions=clf.fit(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "et = pd.merge(baseline_merged,models_et,left_index=True,right_index=True)\n",
    "et1 = et[et.index =='SVC'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']].values.flatten().tolist()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.00, 5.00]\n",
    "sns.barplot(x = et1[::-1] ,y = ['Baseline','Pearson Correlation','Chi Squared','Information Gain','RFE','RFE + Forward Selection'][::-1],palette='Set2',orient='h')\n",
    "plt.ylabel('Selection Method')\n",
    "plt.xlabel('F1 Scores')\n",
    "plt.savefig('svm_final.eps',bbox_inches = 'tight',dpi=1200,transparent= True, format='eps')\n",
    "et[et.index =='SVC'][['F1 Score_baseline','F1 Score_pearson','F1 Score_chi','F1 Score_ig','F1 Score_rfe','F1 Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dce963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bestcols = []\n",
    "# cols = [x for x in result if x['features'] == peak][0]['cols']\n",
    "# features = dt[cols].copy()\n",
    "# target = features.pop('Label')\n",
    "# cols = features.columns.tolist()\n",
    "# feed_forward(cols,bestcols,scoring='recall_macro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe347a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(x=[len(x[1]) for x in bestcols], y=[x[0] for x in bestcols], palette='Set2')\n",
    "# plt.xlabel('Number of Columns')\n",
    "# plt.ylabel('Scores')\n",
    "# plt.show()\n",
    "\n",
    "# bestcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nearest Centroid\n",
    "### Nearest Neighbour\n",
    "### SVC\n",
    "### NB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
