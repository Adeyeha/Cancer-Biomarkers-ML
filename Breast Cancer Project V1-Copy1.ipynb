{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415f2276",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4166f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,cross_validate\n",
    "from sklearn.metrics import classification_report,make_scorer,confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE,ADASYN,BorderlineSMOTE,SMOTEN,SVMSMOTE,KMeansSMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids,RandomUnderSampler,NearMiss\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce519a1c",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e045790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 23873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ffff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_excel(r'CA_BC.xlsx').T\n",
    "dt.columns = dt.iloc[0]\n",
    "dt = dt.iloc[1:]\n",
    "dt['Label'] = dt.Label.map({'E':1,'A':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac0b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.drop_duplicates(keep='first',inplace=True)\n",
    "for x in dt.select_dtypes(include=['object']).columns:\n",
    "    dt[x] = dt[x].astype('float64')\n",
    "dt.columns = [str(x) for x in dt.columns]\n",
    "dt = dt.select_dtypes(include=['float64','int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "970922b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to not rename\n",
    "excluded = dt.columns[~dt.columns.duplicated(keep=False)]\n",
    "\n",
    "# An incrementer\n",
    "import itertools\n",
    "inc = itertools.count().__next__\n",
    "\n",
    "# A renamer\n",
    "def ren(name):\n",
    "    return f\"{name}{inc()}\" if name not in excluded else name\n",
    "\n",
    "# Use inside rename()\n",
    "dt.rename(columns=ren,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca8282",
   "metadata": {},
   "source": [
    "### Baseline Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bfd934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:38<00:00,  1.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "features = dt.copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4ab587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, Balanced Accuracy, ROC AUC, F1 Score, Time Taken]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32fe96",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b27be",
   "metadata": {},
   "source": [
    "### Remove Co-Linear Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648446ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chrisalbon.com/code/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "corr = dt.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223b5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed412919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = corr.abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "print(f\"Would drop {len(to_drop)} fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b068283",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt.drop(to_drop, axis=1).copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_corr,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebee9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ff018",
   "metadata": {},
   "source": [
    "### Check Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb59a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# vif_info = pd.DataFrame()\n",
    "# vif_info['VIF'] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "# vif_info['Column'] = features.columns\n",
    "# vif_info.sort_values('VIF', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef6e03",
   "metadata": {},
   "source": [
    "### Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_MinMax = MinMaxScaler().fit_transform(x_train)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_min_max,predictions=clf.fit(x_train_MinMax, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a65528",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Standard = StandardScaler().fit_transform(x_train)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models_standard,predictions=clf.fit(x_train_Standard, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59122ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da8a88",
   "metadata": {},
   "source": [
    "### Deep Dive on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "features = dt.drop(to_drop, axis=1).copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")\n",
    "\n",
    "imp = pd.DataFrame(data = {'fields':features.columns,'importance':model.coef_[0]}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "imp[imp.importance.abs() >= imp[imp.importance!=0].importance.median()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffa37b",
   "metadata": {},
   "source": [
    "#### Selecting top 10 would not give best result because of negative importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3040e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = imp.head(10).fields.values.tolist() + ['Label']\n",
    "features = dt.drop(to_drop, axis=1)[cols].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449955d",
   "metadata": {},
   "source": [
    "### Recursive Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd652ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_select_log_reg(col):\n",
    "    features = dt[col].copy()\n",
    "    target = features.pop('Label')\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    scoring = {\n",
    "               'balanced_accuracy':'balanced_accuracy',\n",
    "               'f1_macro':'f1_macro',\n",
    "               'precision_macro':'precision_macro',\n",
    "               'recall_macro':'recall_macro',\n",
    "              }\n",
    "\n",
    "    # clf=RandomForestClassifier(n_estimators =10, random_state = 42,class_weight='balanced')\n",
    "    clf = LogisticRegression()\n",
    "    output = cross_validate(pipe, features, target, cv=4, scoring = scoring, return_estimator =True)\n",
    "\n",
    "    imp = pd.DataFrame(data = {'fields':features.columns,'importance':np.mean([estimator.steps[1][1].coef_[0] for estimator in output['estimator']],axis=0)}).sort_values(by='importance',axis=0, ascending=False, inplace=False)\n",
    "    imp = pd.concat([imp[imp.importance <= imp[imp.importance < 0].importance.median()],\n",
    "    imp[imp.importance >= imp[imp.importance > 0].importance.median()]],axis=0)\n",
    "    print(f\"{len(col)} columns produced macro recall of {output['test_recall_macro'].mean()}\")\n",
    "    return {\n",
    "            'features': len(col),\n",
    "            'cols':col,\n",
    "            'medians': (imp[imp.importance < 0].importance.median(),imp[imp.importance > 0].importance.median()),\n",
    "            'balanced_accuracy' :output['test_balanced_accuracy'].mean(),\n",
    "            'f1_macro':output['test_f1_macro'].mean(),\n",
    "            'precision_macro':output['test_precision_macro'].mean(),\n",
    "            'recall_macro':output['test_recall_macro'].mean(),\n",
    "            'balanced_accuracy_std':output['test_balanced_accuracy'].std(),\n",
    "            'f1_macro_std':output['test_f1_macro'].std(),\n",
    "            'precision_macro_std':output['test_precision_macro'].std(),\n",
    "            'recall_macro_std':output['test_recall_macro'].std(),\n",
    "            'next' : imp,\n",
    "            'next_columns' : [x for x in imp.fields.values] + ['Label']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42096b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = dt.drop(to_drop, axis=1).columns\n",
    "features = [0,1]\n",
    "result= []\n",
    "while len(set(features[-5:])) != 1:\n",
    "    res = feat_select_log_reg(col)\n",
    "    result.append(res)\n",
    "    features.append(res['features'])\n",
    "    col = res['next_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res = pd.DataFrame(data = {'features': [res['features'] for res in result],\n",
    "'balanced_accuracy': [res['balanced_accuracy'] for res in result],\n",
    "'f1_macro': [res['f1_macro'] for res in result],\n",
    "'precision_macro': [res['precision_macro'] for res in result],\n",
    "'recall_macro': [res['recall_macro'] for res in result]})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'balanced_accuracy',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Balanced Accuracy')\n",
    "sns.barplot(x = 'features',y = 'f1_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='F1 Macro Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "f, axes = plt.subplots(1, 2)\n",
    "sns.barplot(x = 'features',y = 'precision_macro',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Precision Macro Score')\n",
    "sns.barplot(x = 'features',y = 'recall_macro',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Recall Macro Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = result[[res['features'] for res in result].index(21)]['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37029c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[dd].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60841ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[dd].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d34eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b6001",
   "metadata": {},
   "source": [
    "#### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-20:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt.copy()\n",
    "target = features.pop('Label')\n",
    "cor_support, cor_feature = cor_selector(features, target)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e498a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[cor_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0009c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[cor_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cd908",
   "metadata": {},
   "source": [
    "#### Chi - Square Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f8dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = dt.copy()\n",
    "target = features.pop('Label')\n",
    "\n",
    "X_norm = MinMaxScaler().fit_transform(features)\n",
    "chi_selector = SelectKBest(chi2, k=20)\n",
    "chi_selector.fit(X_norm, target)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = features.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[chi_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[chi_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05744e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "features = dt.copy()\n",
    "target = features.pop('Label')\n",
    "X_norm = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=30, step=1000, verbose=5)\n",
    "rfe_selector.fit(X_norm, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = features.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[rfe_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(features), target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "# Creating the Nearest Centroid Classifier\n",
    "model = LogisticRegression()\n",
    " \n",
    "# Training the classifier\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    " \n",
    "# Printing Accuracy on Training and Test sets\n",
    "print(f\"Training Set Score : {model.score(x_train, y_train) * 100} %\")\n",
    "print(f\"Test Set Score : {model.score(x_test, y_test) * 100} %\")\n",
    " \n",
    "# Printing classification report of classifier on the test set set data\n",
    "print(f\"Model Classification Report : \\n{classification_report(y_test, model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d26849",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dt[rfe_feature + ['Label']].copy()\n",
    "target = features.pop('Label')\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target,stratify=target, test_size=0.3,random_state=random_state)\n",
    "clf=LazyClassifier(verbose=0,ignore_warnings=True,custom_metric=None)\n",
    "models,predictions=clf.fit(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c41f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303899a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75494ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling_mulitple(x_train, y_train):\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    f1_means,f1_std,tss_mean,tss_std,hss2_mean,hss2_std = [],[],[],[],[],[]\n",
    "\n",
    "    classifiers = [LogisticRegression(random_state=random_state),DecisionTreeClassifier(random_state=random_state),\n",
    "                  SVC(random_state=random_state),GaussianNB(),AdaBoostClassifier(random_state=random_state),\n",
    "                    RandomForestClassifier(n_estimators=20,random_state=random_state),XGBClassifier()\n",
    "                  ]\n",
    "\n",
    "    scoring = {'f1_macro': 'f1_macro',\n",
    "               'tss': tss_scorer,\n",
    "               'hss2': hss2_scorer}\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        print(classifier)\n",
    "        scores = cross_validate(classifier, x_train, y_train, scoring=scoring, cv=cv)\n",
    "        f1_means.append(scores['test_f1_macro'].mean())\n",
    "        f1_std.append(scores['test_f1_macro'].std())\n",
    "        tss_mean.append(scores['test_tss'].mean())\n",
    "        tss_std.append(scores['test_tss'].std())\n",
    "        hss2_mean.append(scores['test_hss2'].mean())\n",
    "        hss2_std.append(scores['test_hss2'].std())\n",
    "\n",
    "    cv_res = pd.DataFrame(data={'Algorithms':['LogisticRegression','DecisionTree','SVM','Naive Bayes','AdaBoost',\n",
    "                                              'RandomForest','XGBoost'], 'F1 Mean Score':f1_means, 'F1 std':f1_std,\n",
    "                               'TSS Mean Score':tss_mean, 'TSS std':tss_std, 'HSS2 Mean Score':hss2_mean, 'HSS2 std':hss2_std\n",
    "                               })\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [20.00, 6.00]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    f, axes = plt.subplots(1, 3)\n",
    "\n",
    "    sns.barplot(x = 'F1 Mean Score',y = 'Algorithms',data = cv_res, palette = \"Set2\",ax=axes[0]).set(title='Cross Validation Scores')\n",
    "    sns.barplot(x = 'TSS Mean Score',y = 'Algorithms',data = cv_res, palette = \"Set2\",ax=axes[1]).set(title='Cross Validation Scores')\n",
    "    sns.barplot(x = 'HSS2 Mean Score',y = 'Algorithms',data = cv_res, palette = \"Set2\",ax=axes[2]).set(title='Cross Validation Scores')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef17fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
